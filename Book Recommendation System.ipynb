{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbc9c2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello \n"
     ]
    }
   ],
   "source": [
    "print(\"Hello \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4b1dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdea8c73",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\public\\anaconda3\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# RegEx and String Manipulation\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Language Detection\n",
    "from nltk.classify.textcat import TextCat\n",
    "\n",
    "# Multiprocessing\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing\n",
    "\n",
    "# BERT-Embeddings\n",
    "from keybert import KeyBERT\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Plotting Heatmap of TF-IDF vectors \n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.renderers.enable('mimetype')\n",
    "\n",
    "# Cosine Similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de063e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of words that should be present in a description (value starting from 1)\n",
    "min_description_word_count = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21f40822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256595, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000006</td>\n",
       "      <td>Simple Sermons on Great Christian Doctrines</td>\n",
       "      <td>W. Herschel Ford</td>\n",
       "      <td>0801091241</td>\n",
       "      <td>2001</td>\n",
       "      <td>Baker Books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A collection of simple sermons to help busy pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000007</td>\n",
       "      <td>The Spinoza of Market Street</td>\n",
       "      <td>Isaac Bashevis Singer</td>\n",
       "      <td>0374502560</td>\n",
       "      <td>1979</td>\n",
       "      <td>Farrar, Straus and Giroux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000008</td>\n",
       "      <td>The Golem</td>\n",
       "      <td>Isaac Bashevis Singer</td>\n",
       "      <td>0374427461</td>\n",
       "      <td>1996</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A clay giant miraculously brought to life by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000009</td>\n",
       "      <td>Ujamaa Villages in Tanzania: Analysis of a Soc...</td>\n",
       "      <td>Michaela Von Freyhold</td>\n",
       "      <td>0853455120</td>\n",
       "      <td>1981</td>\n",
       "      <td>Monthly Review Press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000011</td>\n",
       "      <td>Introducing Special Educational Needs: A Guide...</td>\n",
       "      <td>Philip Gardner</td>\n",
       "      <td>1853467332</td>\n",
       "      <td>2001</td>\n",
       "      <td>David Fulton Publishers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pressure of time means that the complex topic ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                               Name  \\\n",
       "0  3000006        Simple Sermons on Great Christian Doctrines   \n",
       "1  3000007                       The Spinoza of Market Street   \n",
       "2  3000008                                          The Golem   \n",
       "3  3000009  Ujamaa Villages in Tanzania: Analysis of a Soc...   \n",
       "4  3000011  Introducing Special Educational Needs: A Guide...   \n",
       "\n",
       "                 Authors        ISBN  PublishYear                  Publisher  \\\n",
       "0       W. Herschel Ford  0801091241         2001                Baker Books   \n",
       "1  Isaac Bashevis Singer  0374502560         1979  Farrar, Straus and Giroux   \n",
       "2  Isaac Bashevis Singer  0374427461         1996       Farrar Straus Giroux   \n",
       "3  Michaela Von Freyhold  0853455120         1981       Monthly Review Press   \n",
       "4         Philip Gardner  1853467332         2001    David Fulton Publishers   \n",
       "\n",
       "  Language                                        Description  \n",
       "0      NaN  A collection of simple sermons to help busy pa...  \n",
       "1      NaN                                                NaN  \n",
       "2      NaN  A clay giant miraculously brought to life by a...  \n",
       "3      NaN                                                NaN  \n",
       "4      NaN  Pressure of time means that the complex topic ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data = pd.read_csv(\"C://Users/personal/Downloads/goodreadbooks/book3000k-4000k.csv\", usecols=['Id', 'Name', 'Authors', 'ISBN', 'PublishYear', 'Publisher', 'Language', 'Description'])\n",
    "display(books_data.shape)\n",
    "books_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6d6e43",
   "metadata": {},
   "source": [
    "#  Text Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d7fcd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.dropna(subset=[\"Description\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d410514c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3724836"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(books_data.Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88833e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mennonites still comprise one of the most markedly rural ethno-religious groups in North America, but are urbanizing faster than other groups. This study illustrates how they have survived, how they are changing, and how they have dealt with internal and external conflict in the process.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(books_data.Description[books_data.Id == 3724836]) #Description with url and html tag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f5285e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96d77cac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_punctuations\u001b[39m(text):\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m text\u001b[38;5;241m.\u001b[39mtranslate(\u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mmaketrans(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, punctuations))\n\u001b[1;32m---> 13\u001b[0m books_data\u001b[38;5;241m.\u001b[39mDescription \u001b[38;5;241m=\u001b[39m \u001b[43mbooks_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDescription\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremove_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m books_data\u001b[38;5;241m.\u001b[39mDescription \u001b[38;5;241m=\u001b[39m books_data\u001b[38;5;241m.\u001b[39mDescription\u001b[38;5;241m.\u001b[39mapply(clean_html_tags)\n\u001b[0;32m     15\u001b[0m books_data\u001b[38;5;241m.\u001b[39mDescription \u001b[38;5;241m=\u001b[39m books_data\u001b[38;5;241m.\u001b[39mDescription\u001b[38;5;241m.\u001b[39mapply(remove_punctuations)\n",
      "File \u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4323\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4324\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4328\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4329\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4330\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4331\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4332\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4431\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4432\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[1;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mremove_url\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_url\u001b[39m(text):   \n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Users\\public\\anaconda3\\lib\\re.py:210\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msub\u001b[39m(pattern, repl, string, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, flags\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    204\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the string obtained by replacing the leftmost\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m    replacement repl.  repl can be either a string or a callable;\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m    if a string, backslash escapes in it are processed.  If it is\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m    a callable, it's passed the Match object and must return\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;124;03m    a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrepl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "def remove_url(text):   \n",
    "    return re.sub(url_pattern, r'', text)\n",
    "\n",
    "html_pattern = re.compile('<[^>]*>')\n",
    "def clean_html_tags(text):\n",
    "    return re.sub(html_pattern, r'', text)\n",
    "\n",
    "punctuations = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "    return text.translate(str.maketrans('', '', punctuations))\n",
    "\n",
    "books_data.Description = books_data.Description.apply(remove_url)\n",
    "books_data.Description = books_data.Description.apply(clean_html_tags)\n",
    "books_data.Description = books_data.Description.apply(remove_punctuations)\n",
    "\n",
    "# Result\n",
    "list(books_data.Description[books_data.Id == 3724836])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d609ffe9",
   "metadata": {},
   "source": [
    "#### Convert Letter Case to Lower and Clip Extra Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8dcb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[[\"Publisher\"]] = books_data[[\"Publisher\"]].fillna(\"unknown\")\n",
    "books_data[[\"Name\", \"Authors\", \"Publisher\", \"Description\"]] = pd.concat([books_data[col].astype(str).str.lower().str.strip() \n",
    "                                                                             for col in [\"Name\", \"Authors\", \"Publisher\", \"Description\"]], \n",
    "                                                                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9068138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Authors</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>PublishYear</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Language</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000006</td>\n",
       "      <td>simple sermons on great christian doctrines</td>\n",
       "      <td>w. herschel ford</td>\n",
       "      <td>0801091241</td>\n",
       "      <td>2001</td>\n",
       "      <td>baker books</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a collection of simple sermons to help busy pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000007</td>\n",
       "      <td>the spinoza of market street</td>\n",
       "      <td>isaac bashevis singer</td>\n",
       "      <td>0374502560</td>\n",
       "      <td>1979</td>\n",
       "      <td>farrar, straus and giroux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000008</td>\n",
       "      <td>the golem</td>\n",
       "      <td>isaac bashevis singer</td>\n",
       "      <td>0374427461</td>\n",
       "      <td>1996</td>\n",
       "      <td>farrar straus giroux</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a clay giant miraculously brought to life by a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000009</td>\n",
       "      <td>ujamaa villages in tanzania: analysis of a soc...</td>\n",
       "      <td>michaela von freyhold</td>\n",
       "      <td>0853455120</td>\n",
       "      <td>1981</td>\n",
       "      <td>monthly review press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000011</td>\n",
       "      <td>introducing special educational needs: a guide...</td>\n",
       "      <td>philip gardner</td>\n",
       "      <td>1853467332</td>\n",
       "      <td>2001</td>\n",
       "      <td>david fulton publishers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pressure of time means that the complex topic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3000014</td>\n",
       "      <td>my lady of cleves</td>\n",
       "      <td>margaret campbell barnes</td>\n",
       "      <td>1402214316</td>\n",
       "      <td>2008</td>\n",
       "      <td>sourcebooks landmark</td>\n",
       "      <td>eng</td>\n",
       "      <td>written by world-reknowned historical novelist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3000015</td>\n",
       "      <td>women and religious writing in early modern en...</td>\n",
       "      <td>erica longfellow</td>\n",
       "      <td>0521837588</td>\n",
       "      <td>2004</td>\n",
       "      <td>cambridge university press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>challenging critical assumptions about the rol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3000023</td>\n",
       "      <td>package printing</td>\n",
       "      <td>nelson eldred</td>\n",
       "      <td>0961630256</td>\n",
       "      <td>1998</td>\n",
       "      <td>crc press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3000024</td>\n",
       "      <td>meat refrigeration</td>\n",
       "      <td>s.j. james</td>\n",
       "      <td>0849315387</td>\n",
       "      <td>2002</td>\n",
       "      <td>crc press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the chilling and freezing of meat remains an e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3000025</td>\n",
       "      <td>kinematic geometry of surface machining</td>\n",
       "      <td>stephen p. radzevich</td>\n",
       "      <td>1420063405</td>\n",
       "      <td>2007</td>\n",
       "      <td>crc press</td>\n",
       "      <td>NaN</td>\n",
       "      <td>the principle of occam's razor loosely transla...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id                                               Name  \\\n",
       "0  3000006        simple sermons on great christian doctrines   \n",
       "1  3000007                       the spinoza of market street   \n",
       "2  3000008                                          the golem   \n",
       "3  3000009  ujamaa villages in tanzania: analysis of a soc...   \n",
       "4  3000011  introducing special educational needs: a guide...   \n",
       "5  3000014                                  my lady of cleves   \n",
       "6  3000015  women and religious writing in early modern en...   \n",
       "7  3000023                                   package printing   \n",
       "8  3000024                                 meat refrigeration   \n",
       "9  3000025            kinematic geometry of surface machining   \n",
       "\n",
       "                    Authors        ISBN  PublishYear  \\\n",
       "0          w. herschel ford  0801091241         2001   \n",
       "1     isaac bashevis singer  0374502560         1979   \n",
       "2     isaac bashevis singer  0374427461         1996   \n",
       "3     michaela von freyhold  0853455120         1981   \n",
       "4            philip gardner  1853467332         2001   \n",
       "5  margaret campbell barnes  1402214316         2008   \n",
       "6          erica longfellow  0521837588         2004   \n",
       "7             nelson eldred  0961630256         1998   \n",
       "8                s.j. james  0849315387         2002   \n",
       "9      stephen p. radzevich  1420063405         2007   \n",
       "\n",
       "                    Publisher Language  \\\n",
       "0                 baker books      NaN   \n",
       "1   farrar, straus and giroux      NaN   \n",
       "2        farrar straus giroux      NaN   \n",
       "3        monthly review press      NaN   \n",
       "4     david fulton publishers      NaN   \n",
       "5        sourcebooks landmark      eng   \n",
       "6  cambridge university press      NaN   \n",
       "7                   crc press      NaN   \n",
       "8                   crc press      NaN   \n",
       "9                   crc press      NaN   \n",
       "\n",
       "                                         Description  \n",
       "0  a collection of simple sermons to help busy pa...  \n",
       "1                                                nan  \n",
       "2  a clay giant miraculously brought to life by a...  \n",
       "3                                                nan  \n",
       "4  pressure of time means that the complex topic ...  \n",
       "5  written by world-reknowned historical novelist...  \n",
       "6  challenging critical assumptions about the rol...  \n",
       "7                                                nan  \n",
       "8  the chilling and freezing of meat remains an e...  \n",
       "9  the principle of occam's razor loosely transla...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e6936",
   "metadata": {},
   "source": [
    "## Remove Book Descriptions With Shorter Length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12823bbe",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'two volumes.', '.', '八丁標の外に出てはいけない―悪鬼と業魔から町を守るために、大人たちが作った忌まわしい伝説。いま伝説が、「実体」となって町に迫る。新しい秩序とは、おびただしい流血でしか生まれないのか。少女は、決死の冒険に身を投じる。', '<i>east asian books</i>', 'country inspired rooms', '根気も集中力もなく、部屋は乱雑、でもそれがおれのライフスタイルさ……などとうそぶく人生の敗者エディが手にした「脳を活性化する薬」。服（の）めば気合充溢、部屋は片づき、企画力も抜群、株では大儲け、ついには実業界の大物の片腕に。でも、そんなうまい話があると思います？\\u3000身におぼえがありすぎて、ちっとも洒落にならない悪夢と破滅の物語。英国推理作家協会新人賞候補、勝ち組と負け組が露骨に表われるニューヨークのビジネス界の世知辛さも見事に描かれています。', '私は他の女の子たちよりも早く老けるだろう。チャイルドモデルから芸能界へ―幼い頃からtvの中で生きてきた美しくすこやかな少女・夕子。ある出来事をきっかけに、彼女はブレイクするが…少女の心とからだに流れる18年の時間を描く。芥川賞受賞第一作。', '<br /><br />', '仇敵を討つ！\\u3000修業に励むナルトに届くアスマの訃報。悲しみに暮れる間もなく、第十班はカカシと共に再び木ノ葉へ潜入する“暁”と対峙する。シカマルの作戦で優位に戦いを進める中、角都の驚愕の能力が明らかに！！', 'no synopsis available.', '...', '《呼蘭河傳》是民國才女蕭紅在香港創作的一部長篇小説，也是她的巔峰之作。小說以作者的家鄉和童年生活為原型，描繪出了作者記憶中的家鄉呼蘭——上世紀二、三十年代一個東北小鎮的單調與美麗、人民的善良與愚昧。全書七章：一、二章寫小城風情，三、四章談家中親疏人物，五、六、七章摹繪獨立旁枝人物。七章可各自獨立又渾然一體。', 'western', 'zwei leidenschaftliche liebesromane.', 'no', '親友のバニラに後れをとりながらも、ショコラは魔界の女王（クイーン）を目指し、人間界で修業中。一方、妖しい魅力の美少年・ピエールが、何の企みか、ショコラに近づいてきて……。大人気マジカル・ラブ・ファンタジー第2弾！', 'biographies.', '額に大きなこぶのあるおじいさんが、山へ木を伐りにいって日が暮れてしまい、お堂で寝ていると、鬼が大勢やってきて歌い踊りはじめました。おもしろくなったおじいさんが、いっしょになって歌い踊ると、鬼たちもよろこんで、明日も来い、額のこぶは預かっておくといって、こぶをとってくれました。翌日隣のおじいさんが真似をして鬼といっしょに踊りますが……。おなじみの昔話の絵本。', 'シリーズ第5作。赤ちゃんだったアカネちゃんは、もうすぐ3さい。モモちゃんも、すっかりおねえちゃんです。ねこのプーとジャムのあいだに、かわいい子ねこが生まれました。それから、いろいろ楽しい事件がおこります。', 'アニメや漫画にひんぱんに登場する「世界征服」。だが、いったい「世界征服」とは何か。あなたが支配者になったらどのタイプになる?このさい徹底的に考えてみよう。', 'なぜ、もっと早くに出会わなかったのだろう――携帯サイトで知り合った女性を殺害した一人の男。再び彼は別の女性と共に逃避行に及ぶ。二人は互いの姿に何を見たのか? 残された家族や友人たちの思い、そして、揺れ動く二人の純愛劇。一つの事件の背景にある、様々な関係者たちの感情を静謐な筆致で描いた渾身の傑作長編。', 'rea', 'previous edition', 'ベッドの枕に置かれた封筒。中には祝福の手紙(「きみはついてるな!」)と25セント硬貨。チップとも呼べない少額すぎるそのコインが、ホテルのメイドにもたらした幸運とは…市井の普通の人間に訪れた特別な瞬間を、名人芸の手業で描いた標題作ほか、天才キングが十年をかけて、瞬間瞬間の全精力を傾注して彫琢した傑作揃い、意外な結末ばかりの全七篇。全篇キング自身の解説つき。', '「祇園精舎の鐘の声，諸行無常の響きあり」－『平家物語』が都の辻々で語られた中世鎌倉時代は，全国各地で新興武士勢力が割拠する一方で，新しい創造性に満ちた仏教が民衆の広い支持を集めた時代だった．本書では源平の争乱から鎌倉幕府成立，蒙古襲来を経て，室町時代の御所で華麗な能楽が舞われた応仁の乱前夜までを活写する．', 's/t: a handbook', '<div>\\n  <p></p>\\n</div>', '江戸に上京して以来音信不通の息子・八郎を捜しに来た母親を手伝うことになった万事屋一行。だが八郎はヤクザ絡みのトラブルに…！？\\u3000他にも桂密着ドキュメントとか団子大食い大会とか…。そしてなんとお妙に許嫁が！？', '今年のバレンタインデーこそ、つかさから直接チョコレートをもらいたい…！！\\u3000綾たちからチョコレートをもらいながら、贅沢な願いを持つ淳平。待ち続けてようやく訪れた至福の時、つかさから衝撃的な発言が出て…！？', 'mystery novel', 'poèmes.', 'x', '《沉香》收录张爱玲以往未曾正式结集出版的散文、电影剧作（包括《不了情》、《太太万岁》、《一曲难忘》、《伊凡生命中的一天》）、亲笔插画和个人遗物的照片。封面装帧极具张爱玲味——封面亮丽的桃红色，参照了张爱玲旗袍面料花瓣的颜色；书中环扉的古蓝色，参照的是张爱玲披肩的颜色；彩插的米黄底色，则是张爱玲毛衣的主色。<br />书中许多细节都是在专家的悉心考证下最后确认的。比如剧本《一曲难忘》是香港科技大学郑树森教授根据油印本整理而成，因为原稿的模糊，也留下了些许存疑文字。张爱玲根据俄罗斯作家索尔仁尼琴《伊凡生命中的一天》改编的广播剧本，则是翻译家乔志高的悉心保存。《不了情》这个连张爱玲自己都痛惜已经散佚的电影，被编者陈子善教授在vcd中发现。可以说，是众多学人披沙拣金般的努力促成了《沉香》的出版幸事。在文集的篇目选择上，还特别收入一本张爱玲的伪书《笑声泪痕》的书影。《沉香》还首次收入了张爱玲生前私人物品的照片。张爱玲过世后，这些物品由遗嘱执行人林式同运至香港交给张爱玲遗产的继承人宋淇夫妇，经宋淇夫妇整理后，再转交台湾皇冠出版公司保存。其中有服饰、鞋子、眼镜、手表、笔、化妆品等。张爱玲的鞋子数量很多，并且都很精致；手表被精心收藏在首饰盒中的暗格里，这些都不同程度地展示出张爱玲的日常生活。', '森羅天頂武闘大会が進行する中、消息を絶ったガリィの行方は、杳として知れなかった。だが、超電磁空手の使い手・刀耳は、「再び相まみえる」という彼女との約束を信じて、リビドー魔獣・アノーマリーと闘い続けた。一方、ゼクスも難敵・木星系連邦ウォーメン609と対決する。伝説の空手家・絶火も参戦し、ますます熱い近未来ハイパー・バトルアクション第11巻!!', 'いよいよ、森羅天頂武闘大会・通称zottが始まった。ルウ奪還の望みを賭け、ガリィはゼクス、ピングらとともに、トーナメントに挑むことになった。しかし、ガリィの心の深淵には死と恐怖の亡霊が巣食い、多くの犠牲を生み出す闘いの意味を掴めずにいた。闘いたくない、でも……!! 立ちはだかる強敵を前に、戸惑い怯えるガリィは、真の戦士として覚醒できるのか!? 白熱のsfハイパー・バトル第5巻!!', \"children's book\", '下ネタを軽快なリズムと痛快なアクションで包みました。強烈なキャラクターが奏でる当代随一のハイテンション不条理ギャグ。', '(peeters 1992)', '(1939 translation)', '不良にからまれ、連れ込まれた公園の水洗トイレから、なぜか異世界へ流されてしまった主人公・渋谷有利。おまけにいきなり「魔王」に指名されて!?\\u3000ｔｖアニメ「今日からマ王！」の原作小説、記念すべき第１弾！', '(文春新書)', '森羅天頂武闘大会・zott第1回戦、ガリィは敵副将クー・ツァンと激突!! 戦うことの真の意味を見い出したガリィには、恐れも戸惑いもなかった。しかし、敵大将のカエルラ・サングウィスと対峙したとき、ガリィの身の内を忌わしい恐怖の記憶が駆け抜ける!! 忘却の彼方に浮かんでは消えるガリィの記憶と、深い謎に封印されたカエルラの過去……。ふたりが再び遭いまみえたことで、運命の歯車は静かに回り始めていた。宿命さえも捩じ伏せる、熱きオーラがほとばしるsfハイパー・バトル第6巻!!', 'おりしもヴァチカンは次期教皇選挙の日。ところが有力候補四人が失踪してしまった……次々起こる見立て殺人。ラングドンは知力の限りを尽くして姿亡き敵を追う！とてつもないスケールで描く驚天動地のラスト！', 'ph 306', 'マークは、一人の男が自殺を図ろうとしている現場に遭遇する。男はある秘密を打ち明け、目の前でピストル自殺を遂げてしまう。十一歳の少年にとってはあまりにも衝撃的な事件だった。秘密を公にすることは即、死につながる。マークは女性弁護士レジーに助けを求める。十一歳の依頼人と女性弁護士が活躍するグリシャム的世界。', 'apparently never published', 'ヨザックを失い、小シマロン王サラレギーと二人だけで、聖砂国内を移動することになったおれ・マ王渋谷有利は……!?\\u3000奇跡のハイテンション・ファンタジー、本編第13弾！', '「yellow」「予感」「stealmoon」などの代表作から約100点のイラストを収録。作品制作秘話から密かな萌えまで!?語り尽くしたロングインタビュー。立野真琴の漫画はこうして生まれる。モノクロ原稿制作過程を完全図解。あの「yellow」の完全新作描き下ろしカラー漫画が読める、極上の一冊。', '大学の女子寮で同室のセンパイ&amp;コウハイ。バンド活動に打ち込むセンパイは、いつも金欠ピーピー状態。これといって打ち込むもののないコウハイは、とりあえず「古本max」でバイト中。ぬるま湯に頭まで浸かったような、でも当人にはそれなりに切実だったりもする「大学生」という不思議な時間…。ぐるぐる廻る青春のアレやコレやを描いた大学生日常ストーリー♪', '「メディア良化法」により、本が狩られる時代。その検閲に対抗すべく、図書館は本を守る防衛隊として「図書隊」を有している。笠原郁は、昔助けてくれた(顔は憶えていない)図書隊員に憧れ入隊。が、待ち受けていたのは「憧れの王子様」ではなく「鬼教官」堂上篤による訓練の数々…!?', 'pulp western.', 'eighth edition', 'grades 6-8.', 'hardbound.', '惨殺された両親の仇討ちを流星に誓いあった三兄妹。<br />「兄貴、妹(あいつ)は本気だよ。俺たちの仇の息子に惚れてるよ」<br />14年後――彼らが仕掛けた復讐計画の最大の誤算は、妹の恋心だった。', '信濃国立石領多岐家では当主が病に倒れ、当主に子がないため甥御を跡を継がせることになっていた。だが、実はお手つきになった女中の静が、秘かに嫡子を生んでいるということを筆頭家老の武部が明かす。その静は、かつてこの藩で剣術指南をしていた男と共に山里に在り…。', 'guillermo roux art.', 'promote brand you', '警察がでっちあげた証人とお粗末な科学捜査により、ロンは死刑判決を下される。12年にもわたる過酷な刑務所暮しがはじまった。刻一刻と迫りくる死刑執行の期日。徐々に彼は精神を蝕まれていったが、そこにdna鑑定という一筋の光明が差し込む…。綿密な取材で捜査当局の不正義を容赦なく白日の下にさらした、全米ベストセラー。', 'ふうちゃんが六年生になった頃、お父さんが心の病気にかかった。お父さんの病気は、どうやら沖縄と戦争に原因があるらしい。なぜ、お父さんの心の中だけ戦争は続くのだろう？\\u3000著者渾身の長編小説！', '受験勉強に追われる早坂ユカリは、単調な日々を送っていたが、服飾専門学校「矢澤芸術学院」に通うジョージの学園祭でファッションモデルを務めることになった。夢を追いかける仲間たちとの出会いは、やがて－－－。 ファッション誌「zipper」で連載。', '「ただの人間には興味ありません。この中に 宇宙人、未来人、超能力者がいたら、あたしのところに来なさい。以上」。入学早々、ぶっ飛んだ挨拶をかましてくれた涼宮八ルヒ。そんなsf小説じゃあるまいし‥‥ と誰でも思うよな。俺も思ったよ。だけど八ルヒは心の底から真剣だったんだ。それに気づいたときには俺の日常は、もうすでに超常になっていた。第8回スニーカー大賞〈大賞〉受賞作、ビミョーに非日常系学園ストーリー！', 'favorite stories.', 'イーノック村を魔物から辛くも守りきったガッツ達だったが、騒ぎの中、キャスカとファルネーゼがトロールによって幽界(かくりょ)の闇の領域“クリフォト”に連れ去られてしまった。救出に向かったガッツは凄まじい戦闘に突入。だが人の理の通じない空間ゆえに“思いもかけない者”が出現!!', 'mirabelle lee', '.<br />', '20 maps', '<p>\\xa0</p>', 'cmh pub 72-3', '大頭春，一個逃家逃學逃社會的孩子，藉著週記，建立起自己的小王國。他的生活週記裡，有確切發生的時事，懵懵懂懂的學習心得，還有人們習以為常或難以消化的胡說八道。他也許是個壞小孩，值得所有的賢明家長和賢明子弟認識。', 'german library', 'on hindu astrology.', 'poems.', 'tunguso-sibirica 3', 'ファンタスティック・忍者コメディー!!<br />「死んだってかまわない」——そう思っていた紅の前に現れたヒーローは、彼女に絶対忠誠を誓う忍者だった!?', '家出少年のホーティがもぐりこんだのは、普通でない人間たちが集うカーニヴァル。団長のモネートルには奇妙な趣味があった。宇宙から来た不思議な水晶の蒐集と研究だ。水晶たちが夢をみるとき、人や動物や植物が生まれる―モネートルはそれを利用して、己の野望を果たそうとしていたのだ。そのことを知ったホーティやカーニヴァルの団員は、恐ろしい運命の渦に巻きこまれていく。幻想sfの巨匠がつむぎだす珠玉の名品。', '平凡なサラリーマンが、ねごとで妻にもらした見知らぬ男への殺意。ねごとでの殺人計画はしだいに具体化していく。はたして、夢の中の出来事なのか、それとも本当は…。他人には信じてもらえない、不思議な事件はいつもどこかで起きている。日常的な時間や空間を超えて展開する非現実的現実世界をウイットあふれる語り口で描く、夢とサスペンスにみちたショートショート21編。', '被害女性の体内で発見された薬莢（やっきょう）から、凶器は２年前に警察が別の事件で押収した銃であることが分かる。新たな殺人が起こり、捜査が進展しない一方で、スカーペッタとベントンの信頼関係に重大な危機が。固い絆を引き裂く“許されざる裏切り”とは何か！\\u3000驚愕必至、予測不能の最終章ですべてが明かされる！\\u3000（講談社文庫）', '17 maps', '這本書收錄了村上最新創作的五部短篇小說，是《神的孩子都會跳舞》之後的最新短篇。以都市奇譚的面貌、將人生體悟與怪誕故事交織，較之之前的短篇小說，村上創作25年的說故事能力越來越讓人嘆為觀止，除了上市後在日本登上暢銷書榜首，更引起美國的注目，紐約客和哈潑雜誌都即時就翻成英文以饗英語讀者。<br /><br />特別薦給喜歡早期聽風的歌、彈珠玩具，35歲以上，結婚超過五年，不論有無小孩的村上讀者。', '-', 'bilder und geschichten', '如果身心做不了主，受環境影響，結果反映出來的都是環境，不但失去了自己，也失去了真正的面目。<br /><br />本書是用一百則禪語的解說，代替教授禪修方法，讓讀者們從禪語的解說中體驗禪修者的心境；遇到困頓逆境時，可以當作避風港；遇到煩惱痛苦時，可以當作清涼散；遇到奈無聊時，可以當作緩和衝撞的手剎車。', 'glycolipids', '今度はなんと銭湯の湯船から異世界へと流されたユーリ。美形で有能な臣下たちと共に、永らく行方不明になっていた「魔剣モルギフ」を探す旅に出たが……。ｔｖアニメ「今日からマ王！」の原作第２弾、《魔剣編》登場', 'メイドvsおっ坊ちゃまのラブ・バトルスタート！<br />誉に恋をしてしまったライバル校の生徒会長・大関は、誉が正宗からひどい扱いを受けていると思いこみ、誉を賭けた剣道の試合を正宗に申し込むが…。', '14歳の秋。生まれて初めての恋。相手は20代後半の絵の先生。ちょっとずつ、ちょっとずつ心の距離を縮めながら仲良くなっていくふたりに、やがて訪れる小さな奇蹟とは...。毎日を生きる私たちに、ひととき魔法をかけてくれる、美しい魂の物語。かわいらしいイラスト満載で、心がぽかぽか温まる宝石のような一冊です。', '&gt;', 'lessons on aesthetics', 'heaven and hell', '世界から憧憬の眼差しが注がれる経済大国？\\u3000それとも、物真似上手のエコノミック・アニマル？\\u3000地球各地で収集したジョークの数々を紹介しながら、適材適所に付された解説により、異国から見た真の日本人像を描き出していきます。『世界の紛争地ジョーク集』『世界反米ジョーク集』に続く、同著者入魂の第三弾は、読者からも問い合わせの多かった「日本人をネタにしたもの」を満載しました。笑って知って、また笑う。一冊で二度おいしい本の誕生です。知的なスパイスの効いた爆笑ネタを、ぜひご賞味あれ！', 'poetry collection', 'textformat=02&gt;', 'rudyard kipling (1865', '落ち目の舞台俳優・トビーは地方巡業先で、離婚訴訟中の妻から助けを求められた。自室が見張られているというのだ。まだ未練が残る妻の身辺を探るうちにトビーが掴んだのは、多くの人命を犠牲にして繁栄した資産家一族の暗部だった。ストーリーテラーの本領発揮!巨匠が放つ最もスピーディーなサスペンス。', 'まんがで描く「源氏物語」全54帖、前人未到の超大作、完結編。大和和紀が情熱をこめて贈る女たちの愛と哀しみの物語。<br /><br />亡き大君に生き写しの浮舟に想いを募らせる薫は、姫を宇治へと伴った。だが、それを知った匂（におう）の宮は浮舟を訪れ、激しく求愛する。誠実な薫の愛に包まれながらも、匂の宮の情熱にふれ、心を乱された浮舟は――。', 'yoke of obedience', '霊を見たり、会話できる不思議な能力を持つ大学生・斉藤八雲。ある日、大学で起こった幽霊騒動を調査することになるが……次々と起こる怪事件の謎に八雲が迫る大人気シリーズ、大幅改稿＆追加エピソード収録で登場。', '很多人認為，舊約聖經似一本封閉的書。他們覺得舊約的世界及文化跟他們很遙遠，內容又繁雜，不易找到明確的思想主線，故此知難而不敢去讀。<br /><br />本書作者是卓越的舊約學者，曾任多間著名學府的講師。他在書中對舊約聖經作了簡明的引介，使讀者瀏覽不多的篇幅，就可全面了解舊約聖經的中心教訓，是理解舊約聖經的入門好書。', 'ハルヒと出会ってから俺はすっかり忘れた言葉だが、あいつの辞書にはいまだに”退屈”という文字が光り輝いているようだ。その証拠に俺たちsos団はハルヒの号令のもと、草野球チームを結成し、七夕祭りに一喜一憂、失踪者の捜索に熱中したかと思えば、わざわざ孤島に出向いて殺人事件に巻き込まれてみたりして。まったく、どれだけ暴れればアイツの気が済むのか想像したくもないね…。非日常系学園ストーリー、天下御免の第３巻！！', 'a golden book.', 'text, translation, commentary', 'ガリオンの谷間でｄを待ち受けていたのは、五千年の眠りから覚めた反陽子コンピュータ“シグマ”だった。ｄはシグマが生み出す幻覚攻撃に耐えて人質の兄妹を救出するが、ブロージュ伯爵を失い、ミランダ公爵夫人も行方不明のままに終わる。兄妹を守って『砦』に向かう孤高のｄに、シグマが生み出す新たなる刺客と、生き残ったヴァルキュアの七人が渾然一体となって襲い掛かった！', '「問題在……她對很多事情都不太容易適應。不管是自己的身體、自己所追求的東西、或別人所要求的東西……」村上春樹<br /><br />村上春樹在無聊又無奈的現實生活中的異想天開，反映了現在都市人孤獨的影子。', '紅家の貧乏お嬢様の秀麗は、彩雲国の若き国王で、即位直後から仕事を放棄している劉輝の貴妃兼教育係を金五百両で引き受けるのだが…!?', 'temples of sovereignty', 'ついに黒い（ノアール）プリンセスになってしまったバニラ。胸の苦しみをこらえ、黒い（ノアール）ハートを集めるバニラと、そんな彼女を救いたいと思いながらも、ピエールへの思いを断ち切れないショコラ。2人の女王（クイーン）候補試験のゆくえは……！？', '四代目火影を超えるために！！\\u3000ナルトの修業も大詰めに入り、sランクの新術会得へと進む。一方、“暁”を探すアスマ班はついにターゲットを捉える！\\u3000奇襲に成功したシカマル達だが、敵の恐るべき能力の前に！？', '白熱する“第三の試験”予選トーナメント！\\u3000我愛羅の対戦相手はリーだった。ヒョウタンの砂を自在に操る我愛羅に対し、鍛えあげた体術だけで立ち向かうリー！！\\u3000超人的な体術でリーは我愛羅を追い込むが…！？', '抱腹絶倒ファンタジー、只今参上!<br />ヤンキーに絡まれたメガネくんを助けて、返り討ちにあった渋谷有利・15歳。トイレに連れ込まれた末に便器に顔を??と思ったらナゼかいきなり異世界に。おまけに俺が魔王って!? 大人気小説がついにコミック化!', 'poetry textbook', '台風のくる二百十日に東北の小さな山村に転校してきた高田三郎を、子どもたちは、伝説の風の子「又三郎」だとして、親しみとおどろきをもってむかえた。宮沢賢治の代表作の1つ『風の又三郎』をはじめ、『どんぐりと山猫』『からすの北斗七星』『ふたごの星』など名作8編を収録。<br /><br />宮沢賢治童話集２', '宇宙人未来人超能力者と一緒に遊ぶのが目的という、正体不明な謎の団体sos団を率いる涼宮ハルヒの目下の関心事は文化祭が楽しくないことらしい。行事を楽しくしたい心意気は大いに結構だが、なにも俺たちが映画を撮らなくてもいいんじゃないか？ハルヒが何か言い出すたびに、周りの宇宙人未来人超能力者が苦労するんだけどな－スニーカー大賞&lt;大賞&gt;を受賞したビミョーに非日常系学園ストーリー、圧倒的人気で第2弾登場！', 'oeuvre de dante', '*', '「光にメロディがあるの?」「あるさ。みんな、そのことに気づいていないだけさ」。“光”を“演奏”することでメッセージを発信する天才高校生・光瑠。彼の「光楽」に、感応し集う若者たち。しかし、その力の大きさを知った大人たちの魔の手が忍び寄る。', '4 audiocassettes', '舞台は沖縄、何かに感謝したくなる、四つの物語。', '水族館のイルカプールから、またまた異世界へと流されたユーリ。吹けば嵐を呼ぶという魔族の秘宝「魔笛」を探しに、人間たちの国へと向かうハメに……。ｔｖアニメ「今日からマ王！」の原作第３弾、《魔笛編》参上！', '新術発動ッ！！\\u3000四代目火影でさえ、成し得なかったナルトの風遁・螺旋手裏剣が角都を打ち砕く…！\\u3000一方、大蛇丸を襲うサスケ。生死をかけた師弟の戦いは非情さを増し…。果たしてサスケの中に残るのは――！？', '灰谷健次郎のライフワーク待望の文庫化！<br /><br />あの倫太郎が中学生になった。不登校、暴力・・・、厳しい子供のいまをじっくりかつ朗らかに描き出す必読の小説。', '電車内で暴れる酔っ払いから若い女性を救った、ヲタク青年。女性に縁がない彼は、彼女をデートに誘うべく、モテない男たちが集うインターネットサイトに助けを求める。いつしか「電車男」と呼ばれるようになった彼に、出来る限りのアドヴァイスを与え、時に叱りながらも温かく見守る仲間たち。熱い励ましは「電車男」に勇気を与え、彼女との距離を一歩一歩縮めていく。「電車男」は果たして意中の彼女に告白できるのか?読む人全てを熱い共感の渦に巻き込む、リアル・ラブ・ストーリー。', '黒（ノアール）に心身ともむしばまれ、眠り続けるバニラを救うため、ショコラは危険を承知で黒（ノアール）ハートを取り出す！ショコラは伝説の“フィルトレ”（浄化する者）だったのだ！しかし、魔界ではやさしかったピエールの心にふたたび黒い影が……！？', 'jan morris (introduction)', '規制緩和の流れに乗ってエネルギー先物取引で急成長を果たしたエンロンは、２００１年12月、史上最大の倒産劇を演じた。グローバルスタンダードへの信頼を一気に失墜させた、その粉飾決算と債務隠しの全容!!', '愛される少年。愛する男。男同士を嫉妬しながら少年を母のように抱く少女。そして、恋人を美少年の魅力から取り戻そうとする黄昏の女の破滅的な情炎。頽廃と純真の綾なす官能の世界を、言葉の贅を尽して描く表題作。愛する少年を奪われる前に殺し、自らも息絶えた男の鮮烈な最期。禁じられた恋の光輝と悲傷を雪の武蔵野に綴る『枯葉の寝床』など、鬼才のロマン全4編を収録。', '白熱する地区予選決勝！\\u3000青学優勝がかかった大事な第4試合、対する不動峰の伊武をおさえ、リョーマのツイストサーブが炸裂！\\u30004ゲーム連取で絶好調と思われた矢先、リョーマの左腕に異変が…。勝負の行方は！？', 'in two volumes.', 'きんぎょが１ぴき、金魚鉢からにげだした。どこににげた？\\u3000カーテンの赤い水玉模様の中にかくれてる。おや、またにげた。こんどは鉢植えで赤い花のふり。おやおや、またにげた。キャンディのびん、盛りつけたイチゴの実の間、おもちゃのロケットの隣……。ページをめくるたびに、にげたきんぎょがどこかにかくれています。子どもたちが大好きな絵探しの絵本。小さな子も指をさしながらきんぎょを探して楽しめます。', 'the comedi', 'ab 11 j.', 'novel in spanish', 'in three volumes.', 'paperback', '結界を張り、三代目火影と相まみえる大蛇丸！！\\u3000秘術、口寄せ“穢土転生”まで用いて、火影を亡きものにしようとする大蛇丸だが…！？\\u3000一方、サスケと我愛羅を追ったナルトたちに大蛇丸の放った刺客が迫り来る！！', 'brown, ann mariedescrip_allowedext_subj_allowed', '服作りに情熱を燃やす“ヤザガク”の４人と出会ってしまった受験生、紫。リーダーのジョージに振り回されつつ、彼らのドレス作りに参加するが成績は下がり始め…。10言語で翻訳、全世界で愛読されている恋とミシンとステージの青春ストーリー！', 'ピエールの策略によってショコラに不信感を抱いたバニラは、ショコラを家から追い出してしまう。<br />戸惑うばかりのショコラ……。<br />そんなショコラを守るため、ウーとソールが魔界からやってきた！', '<p></p>', 'nothing available.', 'ついに一行はクラウハウゼンの村に入った。dは男爵を守り抜き、契約は果たされたのだった。dと別れた男爵は、最後のそして最大の仕事をやり遂げるべく、己れの呪われた過去が秘められた父ヴラドの居城へと向かった。だがそこには、奇怪な老科学者カリオールに率いられた三人の刺客が待ち受けている。ヴラドの魔手は同時にdにも伸び、辺境の村で凄惨な戦いがはじまろうとしていた。', '四人目の仲間に“呪印”の起源・重吾を加えたサスケは、目的達成のための小隊を結成！\\u3000その動きを察知する木ノ葉、“暁”もまた警戒を強める。サスケの標的をイタチに絞ったナルトは、新たな小隊と共に動き出す！！', '夜明けが迫り、影奪回のリミットが近づく。そんな中、モリアはオーズの腹に収まり、益々手に負えない状態に！\\u3000だが、劣勢の一味の前に変身したルフィが現れ！？\\u3000“ひとつなぎの大秘宝”を巡る海洋冒険ロマン！！', 'roman humoristik', '<br />null<br />', 'romantic suspense novel.', '日常生活、風俗習慣から、民話、伝説にいたるまで、近代国家への途上にある日本の忘れられた側面を掘り起こして、古い、美しい、霊的なものを求め続けた小泉八雲（ラフカディオ・ハーン）。彼は、来日後、帰化して骨を埋めるまで、鋭い洞察力と情緒ゆたかな才筆で、日本を広く世界に紹介した。本書は「影」「骨董」「怪談」などの作品集より、代表作を新編集、新訳で収録した。', '<br />', '崩壊寸前の方舟の中、圧倒的な力でティキを退けるクロス元帥！\\u3000しかし千年伯爵が出現し、新たな方舟に転送を加速。それを阻止できるのはアレンだけだという元帥。アレンはピアノのある部屋へ飛ばされて！？', 'essay', 'christian contemporary romance', '=strassburger lectures', '辺境の輸送隊の護衛役を引き受けたｄは、_犠牲者_の娘を伴い、史上最凶の貴族として恐れられていたギャスケル将軍の領地へと向かう。', '55 maps', 'hardcover', 'やり手の広告代理店プランナーが、仕事上で屈辱を味わわされた大手自動車メーカー副社長への復讐を思いつく。仕事も恋愛も人生はすべてゲーム、それに勝ち抜くことがすべてと信じるエリートのプライドが、物語の重要な背景となっている。そこに家出中の副社長の娘が絡み、ラブストーリー的な要素も加わっていく。おのおのの思惑が思わぬ方向に事態を変化させていくあたりは、稀代のストーリーテラーとしての著者の面目躍如だ。', '娘の緑子を連れて豊胸手術のために大阪から上京してきた姉の巻子を迎えるわたし。その三日間に痛快に展開される身体と言葉の交錯!', 'légendes canadiennes.', '口ひげの小男トム、十五歳の少女アリスが仲間に加わった。クレイは彼らとともに最愛の息子の無事を祈りながら「我が家」のあるメイン州を目指す。だがその一方で携帯狂人は群れを形成するようになり、振る舞いも進化していく。そして、リーダーらしき人物の登場……。絶望的なまでに人無き荒野をゆく三人の旅のゆくえと、彼らを襲う悲劇とは。人類の未来をも問う、心揺さぶる結末。', '.html <br />', '家事はまるきり駄目だった茉莉の、ただ一つの例外は料理だった。オムレット、ボルドオ風茸料理、白魚、独活、柱などの清汁…江戸っ子の舌とパリジェンヌの舌を持ち贅沢をこよなく愛した茉莉ならではの得意料理。「百円のイングランド製のチョコレートを一日一個買いに行くのを日課」に、食いしん坊茉莉は夢の食卓を思い描く。垂涎の食エッセイ。', '灰谷健次郎のライフワーク待望の文庫化！<br /><br />あの倫太郎が中学生になった。不登校、暴力・・・厳しい子供たちのいまをじっくりかつ朗らかに描き出す必読の小説。', '巨額の遺産を相続した若い独身女性の家に侵入してみると、なぜかどの部屋のなかも鏡だらけ。意外な結末が待ち受ける「ステップファザー・ステップ」など、すばらしい着想と軽妙なユーモアに彩られた傑作7編', '達海新体制まさかの５連敗！\\u3000本当に怖いのは、負けることじゃない！いい監督は負け方を知っている！！連敗街道に、選手はグッタリ。サポーターはイライラ。それでも達海の目は、前だけを見て光を失わない！！', '全項目を再検討し、新たに1万項目を収録。総収録項目数は24万を超える。新しい意味や用法の広がりを的確に捉え、現代の急速な社会の変動やさまざまな分野での研究の進展、科学技術の進歩に伴って生じた新しい動きを反映。「漢字・難読語一覧」「アルファベット略語」などの別冊付録も充実。印刷・造本上の新工夫も随所に。50年余にわたって読者の信頼を得てきた『広辞苑』、10年ぶりの最新版。', 'vintage paperback', 'sex -- humor', '爽子が理想とする少女・くるみ。だが彼女こそ爽子の親友・千鶴やあやねを中傷するうわさを流し、その犯人に爽子を仕立てた黒幕だった!中学時代から風早を好きだったくるみは、爽子が目ざわりだったのだ。自分の陰湿な行いが風早に知れたら?ふるえるくるみ。風早への想いが恋だと気づいた爽子は、そんなくるみに手をさしのべ…?「別マ」で大好評連載中コミックの小説化・第3弾。', '今なお村人の立ち入りを拒む貴族の城跡のある辺境の村は、陽光の下を徘徊する吸血鬼に怯え、dを雇って対決を要望した。', '郷愁と恐怖、挫折と希望がこの世界を覆う！\\u3000スカーペッタが慣れ親しんだ検屍局が取り壊されることになる。そしてそこにも不審な死の影があった。複雑に絡まる謎が解けた時、待ち受けるかつてない衝撃とは？', '1887', '1982年、オクラホマの小さな町で21歳のウェイトレスが何者かに強姦され殺された。警察の捜査は行き詰まったかに見えたが、事件から5年後、地元に住む元野球選手とその友人が唐突に逮捕された。物的証拠は皆無、全米を震撼させた冤罪事件のはじまりだった…。リーガル・サスペンスの巨匠が挑んだ初のノンフィクション作品。', '87th precinct novel', '首なし死体、密室、蘇る死者、見立て殺人……。京都近郊に建つヨーロッパ中世の古城と見粉うばかりの館・蒼鴉城を「私」が訪れた時、惨劇はすでに始まっていた。2人の名探偵の火花散る対決の行方は。そして迎える壮絶な結末。<br /><br />島田荘司、綾辻行人、法月綸太郎、三氏の圧倒的賛辞を受けた著者のデビュー作。', 'アレックス・クーパーはマンハッタンの地方検察庁で性犯罪訴追課を率いる美貌の女性検事補。ある日、アレックスの別荘に滞在していた親友の女優イザベラが無残な射殺体となって発見された。はたしてアレックスと間違われて犠牲となったのか?捜査を開始したアレックスの身辺に出没する怪しい影。やがて予想外の容疑者の出現に、彼女は絶体絶命の窮地に立たされた!卑劣な犯罪に敢然と立ち向かうニュー・ヒロイン登場。', 'suspense fiction', '「草枕」「雁」「羅生門」などの新しい解読のなかから文学テクストが約束する〈読書のユートピア〉へと読者を誘う。文学研究に新領域を切り開いた著者の最後の仕事。', '新学期を迎え、身体検査の日が近づいて来た。しかしハルヒが女の子であるとバレて、ホスト部にいられなくなってしまうのはマズイ!! そこでホスト部の総力(?)をあげた「ハルちゃんは断じて男の子」作戦が発動され…!?\\u3000短編『ロマンティック・エゴイスト』も併録。', '別れた妻サリーを失意のうちに亡くしプラハに隠れ住むアンバーの前に、18世紀の謎の投書家ジュニアスの名を騙る手紙を携えた男が現れた。その名は23年前彼女と出会い、つらい旅路の始まりとなった、幼い姉妹の誘拐・殺人事件の記憶を呼び覚ます。事件の真相を知るために、アンバーは英国に戻る決意をする。', '何かしなければ、何も変わらない。灰谷健次郎ライフワーク文庫化！<br /><br />倫太郎が通う中学校で４名の少年が検挙された。校舎の窓ガラスを割った疑いらしい。きちんとした対応をとれない学校に対し、教師への違和感は爆発する。そんな中、倫太郎たち、教師、あんちゃんらが一堂に会する。', '雨の日、だるまちゃんが外に遊びにいくと、空から浮き輪とかみなりちゃんが落ちてきました。だるまちゃんは、木に引っかかった浮き輪を取ってあげようと、傘を投げますが、傘もいっしょに引っかかり、二人で困ってしまいました。そこに雲に乗った大きなかみなりどんが迎えにきて、お礼にだるまちゃんをかみなりの国に招待してくれました。未来都市のようなかみなりの国の楽しさも抜群の「だるまちゃん」シリーズ第２作。', 'nan', 'synopsis coming soon.......', 'borges storyreading', 'second edition.', '鮭とごぼうの炊き込みごはん、いわしの梅煮、たけのことがんもとこんにゃくの煮物、栗ごはん、トマトとツナのぶっかけそうめん、鶏肉のオーブン焼き、ナスとトマトと豚肉のピリ辛中華風煮込み、いちごジャムetc.……', '私はたぶん泣きだすべきだったのだ。身も心もみちたりていた恋が終わり、淋しさのあまりねじ切れてしまいそうだったのだから――。濃密な恋がそこなわれていく悲しみを描く表題作のほか、17歳のほろ苦い初デートの思い出を綴った「じゃこじゃこのビスケット」など全12篇。号泣するほどの悲しみが不意におとずれても、きっと大丈夫、切り抜けられる……。そう囁いてくれる直木賞受賞短篇集。', 'なにもかもが奇妙に歪んだ地、この世ならぬ異境で“黒衣の男”を追い続ける孤高の男がいた。最後の“ガンスリンガー”、拳銃使いのローランド。彼はひとりの少年と出会い、ともに旅を続けるが―。“黒衣の男”とは何者なのか?ローランドの過去とは?そして、“暗黒の塔”とは…?幾多の謎を秘めた壮大な探求の旅、ダーク・ファンタジーの金字塔が、いま開幕する。', '男の極楽、女の地獄。<br />ここは遊廓、江戸吉原。', 'guidebook on india.', '向在文壇以「頑童」著稱的小說家張大春，近年創作形式轉向「武俠」類型.這部全書字數長達36 萬字的《城邦暴力團》以其磅礡浩瀚的氣勢、繁複迷離的小說迷宮方式，將成為張大春近年來最具爆炸性的代表作。', '大頭春三部曲結尾，但是一個只有開始的故事。因為後來那些悲慘的事我們都知道了——一開始，誰並不知道，尤其讀者，這是全書唯一的簡單陷阱。', '晚宴歸來臉頰通紅的父親、對著母親頤指氣使的父親、在餐桌上高聲怒斥後躲到廁所偷笑的父親、半夜硬是叫孩子起床吃宴會剩菜的父親、朝長官俯首行禮的父親……', '234.5', 'ターニャの健闘、清良の快進撃。コンクールを見守るのだめは……？<br />カントナ国際コンクール2次予選。清良は順調な演奏で本選進出を決めるもガケっぷちのターニャは実力を発揮できるのか！？一方、コンクールを見守っていたのだめは運命の曲と出会う。「いつか先輩と共演したい！」ラヴェルの協奏曲が宝物になったのだめを残酷な偶然が待ちうけていた……？', '(peeters 1984)', '###############################################################################################################################################################################################################################################################', '武島直貴の兄・剛志は、弟を大学に入れてやりたいという一心から、盗みに入った屋敷で、思いもかけず人を殺めてしまう。判決は、懲役15年。それ以来、直貴のもとへ月に1度、獄中から手紙を送る剛志。一方で、進学、恋人、就職と、つかもうとした人生の幸福すべてが「強盗殺人犯の弟」というレッテルによって、その手をすり抜けていく直貴。日を追うごとに、剛志からの手紙は無視され、捨てられ、やがて…。', '波の音高い海辺の宿は、すでに男ではなくなった老人たちのための逸楽の館であった。真紅のビロードのカーテンをめぐらせた一室に、前後不覚に眠らされた裸形の若い女――その傍らで一夜を過す老人の眼は、みずみずしい娘の肉体を透して、訪れつつある死の相を凝視している。熟れすぎた果実の腐臭に似た芳香を放つデカダンス文学の名作「眠れる美女」のほか「片腕」「散りぬるを」。', 'print on demand', '人はなぜ殺すのか。その答えを探すため、元ｆｂｉ心理分析官ベントンは、収監中の殺人犯と対峙していた。面談のなかで未解決事件の手がかりを得た彼に、惨殺死体発見の知らせが届く。遺体にべたべたと残された赤い手形は何を意味するのか？\\u3000ベントンは助言を得るべく、恋人の検屍官スカーペッタに連絡をとる。（講談社文庫）', '検屍官シリーズ驚愕の新展開で今年も登場！\\u3000フロリダに落ち着いたスカーペッタに古巣バージニア州検屍局からの依頼が届いた。自宅で独り変死した少女は病死か他殺か。わずかな痕跡が新たな事件の幕を開く！', 'one copy', '<b></b>', '『菊と刀』から「日本叩き、日本封じ込め」論まで、日本「独自性」神話をも創り出した。その議論の移り変りを、戦後の流れのなかで捉え直した力作。吉野作造賞受賞のロングセラー。', 'facsimile edition.', '&amp;lt;br /&amp;gt; &amp;gt;', '破天荒な行動力と自由闊達な心を持つ少年、倫太郎の成長を通して、学ぶこと、生きること、自由であることのすばらしさを描く、灰谷文学の集大成。生きることを問うライフワーク。', '大都市の欲望を呑みつくす東京湾。ゴミ、汚物、夢、憎悪……あらゆる残骸が堆積する埋立地。この不安定な領域に浮かんでは消える不可思議な出来事。実は皆が知っているのだ、海が邪悪を胎んでいることを。', '本书介绍了越南南部阮氏王朝的新领土,内区武装力量,外国客商,货币与贸易,阮氏税收制度以及越南人与高原人等内容。', 'complete and unabridged.', '=love letters', '田の想い続けてきた、龍の兄・徹が帰ってきた。吉田の想いが叶わない時、爽子と矢野はそれぞれ吉田のことを思いやり、吉田のことを想う龍も優しく包みこむ。2学期も終わり、クリスマス会が開催される。楽しみな爽子だが…。', '超お金持ち高校・私立桜蘭学院。第三音楽室に迷い込んだ庶民特待生・ハルヒは、「ホスト部」の美麗男子6名と出会う。彼らには関心のないハルヒだったが、部室内の花瓶(800万円!)を割ってしまい、借金返済のためホスト部員になる羽目に…!?', 'libro de cuentos.', '穏やかな陽射しが落ちる秋の一日、ボストン午後3時3分。世界は地獄へと姿を変えた。《パルス》。そのとき携帯電話を使用していたすべての人々が、一瞬にして怪物へと変貌したのだ。残虐極まる行為もいとわず、犠牲を求め続ける凶悪な存在に――。目前で突然繰り広げられる惨劇、街中に溢れる恐怖。クレイは茫然としていた。いったい何が? 別居中の妻と息子は? 巨匠の会心作、開幕!', 'paperback book', '東京大震災から１０年。ある日突然、クラスメイト惨殺の容疑で死刑を宣告された五十嵐丸太。送られた先は日本唯一の完全民営化刑務所「デッドマン・ワンダーランド」だった…。サバイバル監獄アクション開幕！', '本書は、perlをより深く知りそして活用するためのアイデアと、perlによる実践的なプログラミングテクニックをふんだんに盛り込んだレシピ集です（全２冊）。volume 1には、perlの基本データ型、パターンマッチ、ファイルシステムなど基本的な処理のほか、プログラムをフレキシブルで強力にするために欠かせないリファレンス、モジュール、オブジェクトなどに関するレシピを収録。volume 2には、データベースアクセスやユーザインタフェース、ネットワークプログラミング、インターネットサービス、webアプリケーション関連のレシピを収録。また、mod_perlとxmlに関する章を新しく設けています。perlプログラマが直面するプログミングの課題を幅広く取りあげ、そのすべてに実践的な解法を示しています。すべてのperlプログラマへ本書を捧げます。', 'エヌ博士の研究室を襲った強盗。金のもうかる薬を盗んだのはよかったけれど…。女性アレルギーの名探偵のもとに届いた大きな箱。その箱の中に入っていたものは…。別荘で休暇を過すエヌ氏のもとに、突然かかってきた電話。なんとその電話は江戸時代の霊魂からだった…。卓抜なアイデアと奇想天外なユーモアで、不思議な世界にあなたを招待するショートショート31編。', 'a sociological perspective', '莎拉為了救罹患急性前骨髓性白血病的女兒凱特，利用醫學科技生下與凱特有完美基因配型的安娜。十三年來，安娜不斷地供應凱特血液、白血球、骨髓、幹細胞，現在輪到了她的腎臟。無法忍受再被當成藥糧的安娜決定反擊她的父母，控告父母奪走她的身體使用權。《紐約時報》暢銷作家皮考特以不同人物的口吻來接續故事的發展，探討一個極具爭議性的話題；對「愛」有深入的刻劃及詮釋，以細膩的筆法，精妙的細節，靈巧的掌握人與人之間脆弱敏感又錯綜複雜的關係。', 'emmanuelle: the anti-virgin'}\n"
     ]
    }
   ],
   "source": [
    "# Find description word count\n",
    "books_data[\"length\"] = [len(d.split()) for d in books_data['Description'].tolist()]\n",
    "\n",
    "print(set(books_data.Description[books_data.length.isin(range(0,4))]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9928e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000007</td>\n",
       "      <td>the spinoza of market street</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188574</th>\n",
       "      <td>3532943</td>\n",
       "      <td>world history: a dictionary of important peopl...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188575</th>\n",
       "      <td>3532944</td>\n",
       "      <td>tax simplification bills: hearings before the ...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188576</th>\n",
       "      <td>3532945</td>\n",
       "      <td>capital punishment: the inevitability of capri...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188577</th>\n",
       "      <td>3532947</td>\n",
       "      <td>pop photographica: photography's objects in ev...</td>\n",
       "      <td>nan</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id                                               Name  \\\n",
       "1       3000007                       the spinoza of market street   \n",
       "188574  3532943  world history: a dictionary of important peopl...   \n",
       "188575  3532944  tax simplification bills: hearings before the ...   \n",
       "188576  3532945  capital punishment: the inevitability of capri...   \n",
       "188577  3532947  pop photographica: photography's objects in ev...   \n",
       "\n",
       "       Description  length  \n",
       "1              nan       1  \n",
       "188574         nan       1  \n",
       "188575         nan       1  \n",
       "188576         nan       1  \n",
       "188577         nan       1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace empty strings of description with NaN\n",
    "books_data.Description = books_data.Description.replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "books_data[books_data.length.isin(range(1,min_description_word_count+1))][[\"Id\", \"Name\", \"Description\", \"length\"]]\\\n",
    ".sort_values(by=[\"length\"], ascending=True).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99be58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.dropna(subset=[\"Description\"], inplace=True)\n",
    "\n",
    "# Drop records with very short description\n",
    "books_data.drop(books_data.index[books_data.length.isin(range(0,min_description_word_count+1))], inplace = True)\n",
    "del books_data[\"length\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8291943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert unknown to NaN\n",
    "books_data[\"Publisher\"] = books_data.Publisher.replace('unknown',np.nan)\n",
    "books_data = books_data.sort_values(by=\"Publisher\", na_position='last')\\\n",
    ".drop_duplicates(subset=[\"Name\", \"Authors\", \"Description\"], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff5f293",
   "metadata": {},
   "source": [
    "### Extract and Remove Book Series Information from the Book Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6cb30e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_pattern =  \"(?:[;]\\s*|\\(\\s*)([^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*))\"\n",
    "def get_book_series_info(text):\n",
    "    series_info = re.findall(series_pattern, text)\n",
    "    if series_info:\n",
    "        series_info = \" \".join([i.replace(\" \", \"_\") for i in series_info])\n",
    "        return series_info\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "books_data['BookSeriesInfo'] = books_data.Name.apply(get_book_series_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49387cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27522b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_remove_pattern = re.compile(\"(?:[\\(]\\s*[^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*)(?:;|\\))|\\s*[^\\(;]*\\s*#\\s*\\d+(?:\\.?\\d+|\\\\&\\d+|-?\\d*)\\))\")       \n",
    "def remove_series_info(text):\n",
    "    return re.sub(series_remove_pattern, r'', text)\n",
    "\n",
    "books_data[\"Title\"]= books_data[\"Name\"].str.replace(series_remove_pattern, r'').str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bb0623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "404c3d92",
   "metadata": {},
   "source": [
    "###  Impute Missing Language Information Using the Language of the Book Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36b2f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tc = TextCat()\n",
    "\n",
    "def detect_language(text):\n",
    "    text = \" \".join(text.split()[:5])\n",
    "    if text.isnumeric():\n",
    "        return 'eng'\n",
    "    else:\n",
    "        return tc.guess_language(text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86261c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Takes longer time to process thousands records hence results are presaved in preprocessed.csv\n",
    " \"\"\"\n",
    "ddf = dd.from_pandas(books_data, npartitions=4*multiprocessing.cpu_count()) \n",
    "books_data[\"Language\"] = ddf.map_partitions(lambda df: df.apply(lambda x: detect_language(x['Name']) if pd.isna(x['Language']) else x['Language'], axis=1)).compute() \n",
    "books_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_preview = books_data.head(5).copy()\n",
    "ddf = dd.from_pandas(temp_preview, npartitions=4*multiprocessing.cpu_count()) \n",
    "temp_preview[\"Language\"] = ddf.map_partitions(lambda df: df.apply(lambda x: detect_language(x['Name']) if pd.isna(x['Language']) else x['Language'], axis=1)).compute() \n",
    "temp_preview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1661cbc",
   "metadata": {},
   "source": [
    "## Remove Double Quotes from Publisher Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0188bf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[\"Publisher\"] = books_data[\"Publisher\"].str.replace('\"','')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f468c27",
   "metadata": {},
   "source": [
    "## Transform Book and Author Names into Single Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2662e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[\"Authors\"] = books_data[\"Authors\"].str.strip().str.replace(' ','_')\n",
    "books_data[\"Publisher\"] = books_data[\"Publisher\"].str.strip().str.replace(' ','_')\n",
    "books_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8de33aa",
   "metadata": {},
   "source": [
    "###  Merge All the Textual Summary into a Single Summary Column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aaa99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data[\"bow\"] = eda_data[[\"BookSeriesInfo\", 'Authors', 'Publisher', 'Language']].fillna('').agg(' '.join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129d383a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data.bow.iloc[8375]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59733271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "books_data.to_csv(\"C://Users/personal/Downloads/goodreadbooks/preprocessed.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2475fd84",
   "metadata": {},
   "source": [
    "#  Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91fb6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch preprocessed cleaned data\n",
    "fe_data = pd.read_csv(\"C://Users/personal/Downloads/goodreadbooks/preprocessed.csv\", usecols=[\"Id\", \"Name\", \"Language\", \"Description\", \"bow\"])\n",
    "fe_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373e64f8",
   "metadata": {},
   "source": [
    "## Keyword Extraction Using KeyBERT\n",
    "#### Use keyBERT to extract relevant keywords from the Description. It is developed and maintained by Maarten Grootendorst. As stated in its document KeyBERT uses BERT-embeddings and cosine similarity to find the sub-phrases in a document that are the most similar to the document itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f55a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()\n",
    "\n",
    "def get_keywords(text):\n",
    "    keywords = kw_model.extract_keywords(text, keyphrase_ngram_range=(1, 1), stop_words=\"english\")\n",
    "    keywords = \" \".join([k[0] for k in keywords])\n",
    "    return keywords\n",
    "\n",
    "fe_data[\"keywords\"] = fe_data.Description.apply(get_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2753c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data.keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343e669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data[\"keywords\"] = fe_data[['bow', 'keywords']].fillna('').agg(' '.join, axis=1)\n",
    "fe_data.drop(['bow', 'Description'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab27c4",
   "metadata": {},
   "source": [
    "###  Remove duplicated Book Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24904b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe_data = fe_data.drop_duplicates(subset=[\"Name\"], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0ca751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results\n",
    "fe_data.to_csv(\"C://Users/personal/Downloads/goodreadbooks/keywords.csv\", sep=\",\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ce7365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39117c03",
   "metadata": {},
   "source": [
    "# Text Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e8b014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch keywords data\n",
    "model_data = pd.read_csv(\"C://Users/personal/Downloads/goodreadbooks/keywords.csv\")\n",
    "model_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63377f4e",
   "metadata": {},
   "source": [
    "# Vectorize the Keywords Summary Using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fbfe11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(analyzer = 'word',\n",
    "                        min_df=3,\n",
    "                        max_df = 0.6,\n",
    "                        stop_words=\"english\",\n",
    "                        encoding = 'utf-8', \n",
    "                        token_pattern=r\"(?u)\\S\\S+\")\n",
    "tfidf_encoding = tfidf.fit_transform(model_data[\"keywords\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b75532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview first 100 words in the vocabulary\n",
    "print(tfidf.get_feature_names_out()[1:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba76d140",
   "metadata": {},
   "source": [
    "### Visualize the TF-IDF word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3018ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame(tfidf_encoding.toarray(), index=model_data[\"Name\"], columns=tfidf.get_feature_names_out())\n",
    "\n",
    "# Find top 50 books with maximum tf-idf total score\n",
    "tfidf_df[\"total\"]= tfidf_df.sum(axis=1)\n",
    "tfidf_df = tfidf_df.sort_values(\"total\", ascending=False)\n",
    "del tfidf_df[\"total\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1725f5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave first few words containing years and select top 50 books\n",
    "tfidf_df_preview = tfidf_df.iloc[100:150,25:].copy()\n",
    "tfidf_df_preview = tfidf_df_preview.stack().reset_index()\n",
    "tfidf_df_preview = tfidf_df_preview.rename(columns={0:'tfidf', 'Name': 'book','level_1': 'term'})\n",
    "tfidf_df_preview = tfidf_df_preview.sort_values(by=['book','tfidf'], ascending=[True,False]).groupby(['book']).head(10)\n",
    "display(tfidf_df_preview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eacd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_matrix(word_vec):\n",
    "    # Remove underscores in terms\n",
    "    word_vec.term = word_vec.term.str.replace('_',' ')\n",
    "\n",
    "    # Remove terms with zero tfidf score\n",
    "    word_vec = word_vec[word_vec.tfidf > 0]\n",
    "    \n",
    "    return word_vec\n",
    "\n",
    "tfidf_vec = process_word_matrix(tfidf_df_preview.copy())    \n",
    "tfidf_vec.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8400ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "grid = alt.Chart(tfidf_vec).encode(\n",
    "    x = 'rank:O',\n",
    "    y = 'book:N'\n",
    ").transform_window(\n",
    "    rank = \"dense_rank()\",\n",
    "    sort = [alt.SortField(\"tfidf\", order=\"descending\")],\n",
    "    groupby = [\"book\"],\n",
    ")\n",
    "heatmap = grid.mark_rect(size=5).encode(\n",
    "    alt.Color('tfidf:Q', scale=alt.Scale(scheme='redpurple'))\n",
    ")\n",
    "text = grid.mark_text(align='center', baseline='middle', lineBreak='').encode(\n",
    "    text = 'term:N',\n",
    "    color = alt.condition(alt.datum.tfidf >= 0.23, alt.value('white'), alt.value('black'))\n",
    ")\n",
    "(heatmap+text).properties(width = 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73654d05",
   "metadata": {},
   "source": [
    "# Cosine Similarity Between Books Vector Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4977c805",
   "metadata": {},
   "source": [
    "######\n",
    "\n",
    "Once the numerical vector representation of the data is created for each book, it becomes possible to apply all the techniques applicable in a geometric space. It is possible to find similarity between two vectors (and thereby between books represented as vectors). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3549423",
   "metadata": {},
   "outputs": [],
   "source": [
    "book_cosine_sim = cosine_similarity(tfidf_encoding, tfidf_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4455ef1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preview Similarity Matrix\n",
    "book_cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3ed30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vidualize similarity between books\n",
    "plt.figure(figsize=(6, 6), dpi=80)\n",
    "plt.spy(book_cosine_sim, precision = 0.1, markersize = 0.04)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334c12e7",
   "metadata": {},
   "source": [
    "# Recommendation\n",
    "Purpose is: given a book name, find top n similar books based on cosine similarity score. In real use cases, the input book could be the book a user has read, has rated highly or have added to the read later list. Books are recommended utilising the following information through keywords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8793398",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.Series(model_data['Name'])\n",
    "\n",
    "def recommend_books_similar_to(book_name, n=5, cosine_sim_mat=book_cosine_sim):\n",
    "    # get index of the imput book\n",
    "    input_idx = books[books == book_name].index[0]   \n",
    "    # Find top n similar books with decreasing order of similarity score\n",
    "    top_n_books_idx = list(pd.Series(cosine_sim_mat[input_idx]).sort_values(ascending = False).iloc[1:n+1].index)\n",
    "    # [1:6] to exclude 0 (index 0 is the input movie itself)\n",
    "    \n",
    "    books_list = list(books)\n",
    "    recommended_books = [books[i] for i in top_n_books_idx]\n",
    "        \n",
    "    return recommended_books"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6a8983",
   "metadata": {},
   "source": [
    "# 1. Series Information\n",
    "Suggest other books from the similar series.\n",
    "In the example, series information images of america is used to recommend books relating to different parts of America from the same series (new jersey). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe7778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations with series information\n",
    "print(\"\\033[1m{}\\033[0m\".format(\"Recommendation (Series Information) based on the read: The Eastland Disaster (Images of America: Illinois)\"))\n",
    "display(recommend_books_similar_to(\"the eastland disaster (images of america: illinois)\", 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269650aa",
   "metadata": {},
   "source": [
    "# 2. Other Books In Numbered Series\n",
    "Suggest other books in the sequence from the same series.\n",
    "In the example below, other books in the series sequence of Antique Lover are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommendations with series information numbered\n",
    "print(\"\\n\\033[1m{}\\033[0m\".format(\"Recommendation (Numbered Series) based on the read: The Majolica Murders (Antique Lover, #5)\"))\n",
    "display(recommend_books_similar_to(\"the majolica murders (antique lover, #5)\", 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0700d9",
   "metadata": {},
   "source": [
    "# 3.Theme\n",
    "Utilise keywords depicting semantic meaning of the theme of the book to suggest books from similar themes.\n",
    "In the example below, all the books about developing programming skills irrespective of programming language are recommended."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d041c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1m{}\\033[0m\".format(\"Recommendation (Theme: Programming) based on the read: The Practice of Programming (Addison-Wesley Professional Computing Series)\"))\n",
    "display(recommend_books_similar_to('the practice of programming (addison-wesley professional computing series)', 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55946b51",
   "metadata": {},
   "source": [
    "# 4. Author\n",
    "Suggest other works of the same Author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab7c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\033[1m{}\\033[0m\".format(\"Recommendation (Author: Dean Koontz) based on the read: Cold Fire\"))\n",
    "display(recommend_books_similar_to(\"cold fire\",5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e9516b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
